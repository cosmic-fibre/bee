const char csv_lua[] =
"--- Read a comma or tab (or other delimiter) separated file.\n"
"--  This version of a CSV reader differs from others I've seen in that it\n"
"--\n"
"--  + handles embedded newlines in fields (if they're delimited with double\n"
"--    quotes)\n"
"--  + is line-ending agnostic\n"
"--  + reads the file line-by-line, so it can potientially handle large\n"
"--    files.\n"
"--\n"
"--  Of course, for such a simple format, CSV is horribly complicated, so it\n"
"--  likely gets something wrong.\n"
"\n"
"--  (c) Copyright 2013-2014 Incremental IP Limited.\n"
"--  (c) Copyright 2014 Kevin Martin\n"
"--  Available under the MIT licence.  See LICENSE for more information.\n"
"\n"
"local DEFAULT_BUFFER_BLOCK_SIZE = 1024 * 1024\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"local function trim_space(s)\n"
"  return s:match(\"^%s*(.-)%s*$\")\n"
"end\n"
"\n"
"\n"
"local function fix_quotes(s)\n"
"  -- the sub(..., -2) is to strip the trailing quote\n"
"  return string.sub(s:gsub('\"\"', '\"'), 1, -2)\n"
"end\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"local column_map = {}\n"
"column_map.__index = column_map\n"
"\n"
"\n"
"local function normalise_string(s)\n"
"  return (s:lower():gsub(\"[^%w%d]+\", \" \"):gsub(\"^ *(.-) *$\", \"%1\"))\n"
"end\n"
"\n"
"\n"
"--- Parse a list of columns.\n"
"--  The main job here is normalising column names and dealing with columns\n"
"--  for which we have more than one possible name in the header.\n"
"function column_map:new(columns)\n"
"  local name_map = {}\n"
"  for n, v in pairs(columns) do\n"
"    local names\n"
"    local t\n"
"    if type(v) == \"table\" then\n"
"      t = { transform = v.transform, default = v.default }\n"
"      if v.name then\n"
"        names = { normalise_string(v.name) }\n"
"      elseif v.names then\n"
"        names = v.names\n"
"        for i, n in ipairs(names) do names[i] = normalise_string(n) end\n"
"      end\n"
"    else\n"
"      if type(v) == \"function\" then\n"
"        t = { transform = v }\n"
"      else\n"
"        t = {}\n"
"        if type(v) == \"string\" then\n"
"          names = { normalise_string(v) }\n"
"        end\n"
"      end\n"
"    end\n"
"\n"
"    if not names then\n"
"      names = { (n:lower():gsub(\"[^%w%d]+\", \" \")) }\n"
"    end\n"
"\n"
"    t.name = n\n"
"    for _, n in ipairs(names) do\n"
"      name_map[n:lower()] = t\n"
"    end\n"
"  end\n"
"\n"
"  return setmetatable({ name_map = name_map }, column_map)\n"
"end\n"
"\n"
"\n"
"--- Map \"virtual\" columns to file columns.\n"
"--  Once we've read the header, work out which columns we're interested in and\n"
"--  what to do with them.  Mostly this is about checking we've got the columns\n"
"--  we need and writing a nice complaint if we haven't.\n"
"function column_map:read_header(header)\n"
"  local index_map = {}\n"
"\n"
"  -- Match the columns in the file to the columns in the name map\n"
"  local found = {}\n"
"  local found_any\n"
"  for i, word in ipairs(header) do\n"
"    word = normalise_string(word)\n"
"    local r = self.name_map[word]\n"
"    if r then\n"
"      index_map[i] = r\n"
"      found[r.name] = true\n"
"      found_any = true\n"
"    end\n"
"  end\n"
"\n"
"  if not found_any then return end\n"
"\n"
"  -- check we found all the columns we need\n"
"  local not_found = {}\n"
"  for name, r in pairs(self.name_map) do\n"
"    if not found[r.name] then\n"
"      local nf = not_found[r.name]\n"
"      if nf then\n"
"        nf[#nf+1] = name\n"
"      else\n"
"        not_found[r.name] = { name }\n"
"      end\n"
"    end\n"
"  end\n"
"  -- If any columns are missing, assemble an error message\n"
"  if next(not_found) then\n"
"    local problems = {}\n"
"    for k, v in pairs(not_found) do\n"
"      local missing\n"
"      if #v == 1 then\n"
"        missing = \"'\"..v[1]..\"'\"\n"
"      else\n"
"        missing = v[1]\n"
"        for i = 2, #v - 1 do\n"
"          missing = missing..\", '\"..v[i]..\"'\"\n"
"        end\n"
"        missing = missing..\" or '\"..v[#v]..\"'\"\n"
"      end\n"
"      problems[#problems+1] = \"Couldn't find a column named \"..missing\n"
"    end\n"
"    error(table.concat(problems, \"\\n\"), 0)\n"
"  end\n"
"\n"
"  self.index_map = index_map\n"
"  return true\n"
"end\n"
"\n"
"\n"
"function column_map:transform(value, index)\n"
"  local field = self.index_map[index]\n"
"  if field then\n"
"    if field.transform then\n"
"      local ok\n"
"      ok, value = pcall(field.transform, value)\n"
"      if not ok then\n"
"        error((\"Error reading field '%s': %s\"):format(field.name, value), 0)\n"
"      end\n"
"    end\n"
"    return value or field.default, field.name\n"
"  end\n"
"end\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"local file_buffer = {}\n"
"file_buffer.__index = file_buffer\n"
"\n"
"function file_buffer:new(file, buffer_block_size)\n"
"  return setmetatable({\n"
"      file              = file,\n"
"      buffer_block_size = buffer_block_size or DEFAULT_BUFFER_BLOCK_SIZE,\n"
"      buffer_start      = 0,\n"
"      buffer            = \"\",\n"
"    }, file_buffer)\n"
"end\n"
"\n"
"\n"
"--- Cut the front off the buffer if we've already read it\n"
"function file_buffer:truncate(p)\n"
"  p = p - self.buffer_start\n"
"  if p > self.buffer_block_size then\n"
"    local remove = self.buffer_block_size *\n"
"      math.floor((p-1) / self.buffer_block_size)\n"
"    self.buffer = self.buffer:sub(remove + 1)\n"
"    self.buffer_start = self.buffer_start + remove\n"
"  end\n"
"end\n"
"\n"
"\n"
"--- Find something in the buffer, extending it if necessary\n"
"function file_buffer:find(pattern, init)\n"
"  while true do\n"
"    local first, last, capture =\n"
"      self.buffer:find(pattern, init - self.buffer_start)\n"
"    -- if we found nothing, or the last character is at the end of the\n"
"    -- buffer (and the match could potentially be longer) then read some\n"
"    -- more.\n"
"    if not first or last == #self.buffer then\n"
"      local s = self.file:read(self.buffer_block_size)\n"
"      if not s then\n"
"        if not first then\n"
"          return\n"
"        else\n"
"          return first + self.buffer_start, last + self.buffer_start, capture\n"
"        end\n"
"      end\n"
"      self.buffer = self.buffer..s\n"
"    else\n"
"      return first + self.buffer_start, last + self.buffer_start, capture\n"
"    end\n"
"  end\n"
"end\n"
"\n"
"\n"
"--- Extend the buffer so we can see more\n"
"function file_buffer:extend(offset)\n"
"  local extra = offset - #self.buffer - self.buffer_start\n"
"  if extra > 0 then\n"
"    local size = self.buffer_block_size *\n"
"      math.ceil(extra / self.buffer_block_size)\n"
"    local s = self.file:read(size)\n"
"    if not s then return end\n"
"    self.buffer = self.buffer..s\n"
"  end\n"
"end\n"
"\n"
"\n"
"--- Get a substring from the buffer, extending it if necessary\n"
"function file_buffer:sub(a, b)\n"
"  self:extend(b)\n"
"  b = b == -1 and b or b - self.buffer_start\n"
"  return self.buffer:sub(a - self.buffer_start, b)\n"
"end\n"
"\n"
"\n"
"--- Close a file buffer\n"
"function file_buffer:close()\n"
"  self.file:close()\n"
"  self.file = nil\n"
"end\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"local separator_candidates = { \",\", \"\\t\", \"|\" }\n"
"local guess_separator_params = { record_limit = 8; }\n"
"\n"
"\n"
"local function try_separator(buffer, sep, f)\n"
"  guess_separator_params.separator = sep\n"
"  local min, max = math.huge, 0\n"
"  local lines, split_lines = 0, 0\n"
"  local iterator = coroutine.wrap(function() f(buffer, guess_separator_params) end)\n"
"  for t in iterator do\n"
"    min = math.min(min, #t)\n"
"    max = math.max(max, #t)\n"
"    split_lines = split_lines + (t[2] and 1 or 0)\n"
"    lines = lines + 1\n"
"  end\n"
"  if split_lines / lines > 0.75 then\n"
"    return max - min\n"
"  else\n"
"    return math.huge\n"
"  end\n"
"end\n"
"\n"
"\n"
"--- If the user hasn't specified a separator, try to work out what it is.\n"
"function guess_separator(buffer, f)\n"
"  local best_separator, lowest_diff = \"\", math.huge\n"
"  for _, s in ipairs(separator_candidates) do\n"
"    local ok, diff = pcall(function() return try_separator(buffer, s, f) end)\n"
"    if ok and diff < lowest_diff then\n"
"      best_separator = s\n"
"      lowest_diff = diff\n"
"    end\n"
"  end\n"
"\n"
"  return best_separator\n"
"end\n"
"\n"
"\n"
"local unicode_BOMS =\n"
"{\n"
"  {\n"
"    length = 2,\n"
"    BOMS =\n"
"    {\n"
"      [\"\\254\\255\"]      = true, -- UTF-16 big-endian\n"
"      [\"\\255\\254\"]      = true, -- UTF-16 little-endian\n"
"    }\n"
"  },\n"
"  {\n"
"    length = 3,\n"
"    BOMS =\n"
"    {\n"
"      [\"\\239\\187\\191\"]  = true, -- UTF-8\n"
"    }\n"
"  }\n"
"}\n"
"\n"
"\n"
"local function find_unicode_BOM(sub)\n"
"  for _, x in ipairs(unicode_BOMS) do\n"
"    local code = sub(1, x.length)\n"
"    if x.BOMS[code] then\n"
"      return x.length\n"
"    end\n"
"  end\n"
"  return 0\n"
"end\n"
"\n"
"\n"
"--- Iterate through the records in a file\n"
"--  Since records might be more than one line (if there's a newline in quotes)\n"
"--  and line-endings might not be native, we read the file in chunks of\n"
"--  we read the file in chunks using a file_buffer, rather than line-by-line\n"
"--  using io.lines.\n"
"local function separated_values_iterator(buffer, parameters)\n"
"  local field_start = 1\n"
"\n"
"  local advance\n"
"  if buffer.truncate then\n"
"    advance = function(n)\n"
"      field_start = field_start + n\n"
"      buffer:truncate(field_start)\n"
"    end\n"
"  else\n"
"    advance = function(n)\n"
"      field_start = field_start + n\n"
"    end\n"
"  end\n"
"\n"
"\n"
"  local function field_sub(a, b)\n"
"    b = b == -1 and b or b + field_start - 1\n"
"    return buffer:sub(a + field_start - 1, b)\n"
"  end\n"
"\n"
"\n"
"  local function field_find(pattern, init)\n"
"    init = init or 1\n"
"    local f, l, c = buffer:find(pattern, init + field_start - 1)\n"
"    if not f then return end\n"
"    return f - field_start + 1, l - field_start + 1, c\n"
"  end\n"
"\n"
"\n"
"  -- Is there some kind of Unicode BOM here?\n"
"  advance(find_unicode_BOM(field_sub))\n"
"\n"
"\n"
"  -- Start reading the file\n"
"  local sep = \"([\"..(parameters.separator or\n"
"                     guess_separator(buffer, separated_values_iterator))..\"\\n\\r])\"\n"
"  local line_start = 1\n"
"  local line = 1\n"
"  local field_count, fields, starts, nonblanks = 0, {}, {}\n"
"  local header, header_read\n"
"  local field_start_line, field_start_column\n"
"  local record_count = 0\n"
"\n"
"\n"
"  local function problem(message)\n"
"    error((\"%s:%d:%d: %s\"):\n"
"      format(parameters.filename, field_start_line, field_start_column,\n"
"             message), 0)\n"
"  end\n"
"\n"
"\n"
"  while true do\n"
"    local field_end, sep_end, this_sep\n"
"    local tidy\n"
"    field_start_line = line\n"
"    field_start_column = field_start - line_start + 1\n"
"\n"
"    -- If the field is quoted, go find the other quote\n"
"    if field_sub(1, 1) == '\"' then\n"
"      advance(1)\n"
"      local current_pos = 0\n"
"      repeat\n"
"        local a, b, c = field_find('\"(\"?)', current_pos + 1)\n"
"        current_pos = b\n"
"      until c ~= '\"'\n"
"      if not current_pos then problem(\"unmatched quote\") end\n"
"      tidy = fix_quotes\n"
"      field_end, sep_end, this_sep = field_find(\" *([^ ])\", current_pos+1)\n"
"      if this_sep and not this_sep:match(sep) then problem(\"unmatched quote\") end\n"
"    else\n"
"      field_end, sep_end, this_sep = field_find(sep, 1)\n"
"      tidy = trim_space\n"
"    end\n"
"\n"
"    -- Look for the separator or a newline or the end of the file\n"
"    field_end = (field_end or 0) - 1\n"
"\n"
"    -- Read the field, then convert all the line endings to \\n, and\n"
"    -- count any embedded line endings\n"
"    local value = field_sub(1, field_end)\n"
"    value = value:gsub(\"\\r\\n\", \"\\n\"):gsub(\"\\r\", \"\\n\")\n"
"    for nl in value:gmatch(\"\\n()\") do\n"
"      line = line + 1\n"
"      line_start = nl + field_start\n"
"    end\n"
"\n"
"    value = tidy(value)\n"
"    if #value > 0 then nonblanks = true end\n"
"    field_count = field_count + 1\n"
"\n"
"    -- Insert the value into the table for this \"line\"\n"
"    local key\n"
"    if parameters.column_map and header_read then\n"
"      local ok\n"
"      ok, value, key = pcall(parameters.column_map.transform,\n"
"        parameters.column_map, value, field_count)\n"
"      if not ok then problem(value) end\n"
"    elseif header then\n"
"      key = header[field_count]\n"
"    else\n"
"      key = field_count\n"
"    end\n"
"    if key then\n"
"      fields[key] = value\n"
"      starts[key] = { line=field_start_line, column=field_start_column }\n"
"    end\n"
"\n"
"    -- if we ended on a newline then yield the fields on this line.\n"
"    if not this_sep or this_sep == \"\\r\" or this_sep == \"\\n\" then\n"
"      if parameters.column_map and not header_read then\n"
"        header_read = parameters.column_map:read_header(fields)\n"
"      elseif parameters.header and not header_read then\n"
"        if nonblanks or field_count > 1 then -- ignore blank lines\n"
"          header = fields\n"
"          header_read = true\n"
"        end\n"
"      else\n"
"        if nonblanks or field_count > 1 then -- ignore blank lines\n"
"          coroutine.yield(fields, starts)\n"
"          record_count = record_count + 1\n"
"          if parameters.record_limit and\n"
"             record_count >= parameters.record_limit then\n"
"            break\n"
"          end\n"
"        end\n"
"      end\n"
"      field_count, fields, starts, nonblanks = 0, {}, {}\n"
"    end\n"
"\n"
"    -- If we *really* didn't find a separator then we're done.\n"
"    if not sep_end then break end\n"
"\n"
"    -- If we ended on a newline then count it.\n"
"    if this_sep == \"\\r\" or this_sep == \"\\n\" then\n"
"      if this_sep == \"\\r\" and field_sub(sep_end+1, sep_end+1) == \"\\n\" then\n"
"        sep_end = sep_end + 1\n"
"      end\n"
"      line = line + 1\n"
"      line_start = field_start + sep_end\n"
"    end\n"
"\n"
"    advance(sep_end)\n"
"  end\n"
"end\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"local buffer_mt =\n"
"{\n"
"  lines = function(t)\n"
"      return coroutine.wrap(function()\n"
"          separated_values_iterator(t.buffer, t.parameters)\n"
"        end)\n"
"    end,\n"
"  close = function(t)\n"
"      if t.buffer.close then t.buffer:close() end\n"
"    end,\n"
"  name = function(t)\n"
"      return t.parameters.filename\n"
"    end,\n"
"}\n"
"buffer_mt.__index = buffer_mt\n"
"\n"
"\n"
"--- Use an existing file or buffer as a stream to read csv from.\n"
"--  (A buffer is just something that looks like a string in that we can do\n"
"--  `buffer:sub()` and `buffer:find()`)\n"
"--  @return a file object\n"
"local function use(\n"
"  buffer,           -- ?string|file|buffer: the buffer to read from.  If it's:\n"
"                    --   - a string, read from that;\n"
"                    --   - a file, turn it into a file_buffer;\n"
"                    --   - nil, read from stdin\n"
"                    -- otherwise assume it's already a a buffer.\n"
"  parameters)       -- ?table: parameters controlling reading the file.\n"
"                    -- See README.md\n"
"  parameters = parameters or {}\n"
"  parameters.filename = parameters.filename or \"<unknown>\"\n"
"  parameters.column_map = parameters.columns and\n"
"    column_map:new(parameters.columns)\n"
"\n"
"  if not buffer then\n"
"    buffer = file_buffer:new(io.stdin)\n"
"  elseif io.type(buffer) == \"file\" then\n"
"    buffer = file_buffer:new(buffer)\n"
"  end\n"
"\n"
"  local f = { buffer = buffer, parameters = parameters }\n"
"  return setmetatable(f, buffer_mt)\n"
"end\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"--- Open a file for reading as a delimited file\n"
"--  @return a file object\n"
"local function open(\n"
"  filename,         -- string: name of the file to open\n"
"  parameters)       -- ?table: parameters controlling reading the file.\n"
"                    -- See README.md\n"
"  local file, message = io.open(filename, \"r\")\n"
"  if not file then return nil, message end\n"
"\n"
"  parameters = parameters or {}\n"
"  parameters.filename = filename\n"
"  return use(file_buffer:new(file), parameters)\n"
"end\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"local function makename(s)\n"
"  local t = {}\n"
"  t[#t+1] = \"<(String) \"\n"
"  t[#t+1] = (s:gmatch(\"[^\\n]+\")() or \"\"):sub(1,15)\n"
"  if #t[#t] > 14 then t[#t+1] = \"...\" end\n"
"  t[#t+1] = \" >\"\n"
"  return table.concat(t)\n"
"end\n"
"\n"
"\n"
"--- Open a string for reading as a delimited file\n"
"--  @return a file object\n"
"local function openstring(\n"
"  filecontents,     -- string: The contents of the delimited file\n"
"  parameters)       -- ?table: parameters controlling reading the file.\n"
"                    -- See README.md\n"
"\n"
"  parameters = parameters or {}\n"
"\n"
"\n"
"  parameters.filename = parameters.filename or makename(filecontents)\n"
"  parameters.buffer_size = parameters.buffer_size or #filecontents\n"
"  return use(filecontents, parameters)\n"
"end\n"
"\n"
"\n"
"------------------------------------------------------------------------------\n"
"\n"
"return { open = open, openstring = openstring, use = use }\n"
"\n"
"------------------------------------------------------------------------------\n"
""
;
